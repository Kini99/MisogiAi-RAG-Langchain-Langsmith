# ğŸ¦ Banking AI Assistant (LangChain + Chroma)

This project implements an **AI-powered Retrieval-Augmented Generation (RAG) assistant** for banks, capable of answering questions about **loan products, regulatory requirements, and internal policies**.  

It uses the **LangChain framework** for document processing, embeddings, retrieval, and orchestration, with **Chroma** as the local vector store.  

---

## ğŸ“Œ Features

- **Document Processing**
  - Handles diverse banking documents: loan handbooks, compliance manuals, policy docs, and rate sheets  
  - Preprocessing and chunking using custom strategies to reduce table context loss  

- **Vector Search**
  - Uses **Chroma** for embedding storage and retrieval  
  - Optimized for handling cross-references and structured data  

- **RAG Pipeline**
  - Built on **LangChain RetrievalQA**  
  - Supports conversational context with memory  
  - Integrates custom LLM manager for flexible model usage  

- **Evaluation Datasets**
  - Includes test sets for loan products, compliance, and table cross-references  

- **Frontend Prototype**
  - Basic interface to interact with the assistant  
  - Launchable with `run_frontend.py`  

---

## ğŸ—‚ Project Structure

```
banking-assistant/
â”‚â”€â”€ main.py                     # Entry point
â”‚â”€â”€ example_usage.py             # Example usage script
â”‚â”€â”€ requirements.txt             # Backend dependencies
â”‚â”€â”€ frontend.py                  # Streamlit/Gradio frontend
â”‚â”€â”€ run_frontend.py              # Run frontend server
â”‚â”€â”€ FRONTEND_README.md           # Frontend setup instructions
â”‚â”€â”€ Cost-Effective_RAG_Implementation_Guide.md
â”‚â”€â”€ IMPLEMENTATION_SUMMARY.md
â”‚â”€â”€ datasets/                    # Evaluation datasets
â”‚â”€â”€ sample_documents/            # Example banking documents
â”‚â”€â”€ chroma_db/                   # Local vector database
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ api.py                   # API endpoints
â”‚   â”œâ”€â”€ banking_assistant.py     # Core RAG pipeline
â”‚   â”œâ”€â”€ document_processor.py    # Document loading & chunking
â”‚   â”œâ”€â”€ llm_manager.py           # LLM integration layer
â”‚   â””â”€â”€ config.py                # Configuration
```

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone Repository
```bash
git clone https://github.com/your-username/banking-ai-assistant.git
cd banking-ai-assistant
```

### 2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Setup Environment
- Copy `.env` or use `env_template.txt`  
- Add your API keys (e.g., OpenAI, HuggingFace)  

### 4ï¸âƒ£ Run Backend
```bash
python main.py
```

### 5ï¸âƒ£ Run Frontend
```bash
python run_frontend.py
```

---

## ğŸ“Š Cost Optimization

See **[Cost-Effective RAG Implementation Guide](./Cost-Effective_RAG_Implementation_Guide.md)** for detailed analysis of:  
- Premium setup (e.g., GPT-4 + Pinecone)  
- Optimized setup (e.g., Local LLM + Chroma)  
- Hybrid approaches with trade-offs & ROI  

---

## ğŸ“š Resources

- [LangChain Documentation](https://docs.langchain.com/)  
- [Chroma Vector DB](https://www.trychroma.com/)  

---

## ğŸ› ï¸ Future Improvements

- Enhanced table-aware chunking  
- Multi-modal document support (PDFs with images/diagrams)  
- Advanced evaluation with LangSmith  

---
